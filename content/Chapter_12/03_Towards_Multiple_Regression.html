
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>12.3. Towards Multiple Regression &#8212; Data 88S Textbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/Chapter_12/03_Towards_Multiple_Regression';</script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="12.4. Exercises" href="04_Exercises.html" />
    <link rel="prev" title="12.2. The Distribution of the Estimated Slope" href="02_The_Distribution_of_the_Estimated_Slope.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/data88s_logo.png" class="logo__image only-light" alt="Data 88S Textbook - Home"/>
    <script>document.write(`<img src="../../_static/data88s_logo.png" class="logo__image only-dark" alt="Data 88S Textbook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="http://stat88.org">Course Home</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_01/00_The_Basics.html">1. The Basics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/01_Probabilities_as_Proportions.html">1.1. Probabilities as Proportions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/02_Exact_Calculation_or_Bound.html">1.2. Exact Calculation, or Bound?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/03_Fundamental_Rules.html">1.3. Fundamental Rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/04_Exercises.html">1.4. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_02/00_Intersections_and_Conditioning.html">2. Intersections and Conditioning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/01_The_Chance_of_an_Intersection.html">2.1. The Chance of an Intersection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/02_Symmetry_in_Simple_Random_Sampling.html">2.2. Symmetry in Simple Random Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/03_Bayes_Rule.html">2.3. Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/04_Use_and_Interpretation.html">2.4. Use and Interpretation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/05_Independence.html">2.5. Independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/06_Exercises.html">2.6. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_03/00_Random_Counts.html">3. Random Counts</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/01_Success_and_Failure.html">3.1. Success and Failure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/02_Random_Variables.html">3.2. Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/03_The_Binomial_Distribution.html">3.3. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/04_The_Hypergeometric_Distribution.html">3.4. The Hypergeometric Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/05_Examples.html">3.5. Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/06_Exercises.html">3.6. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_04/00_Infinitely_Many_Values.html">4. Infinitely Many Values</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/01_Cumulative_Distribution_Function.html">4.1. Cumulative Distribution Function (CDF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/02_Waiting_Times.html">4.2. Waiting Times</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/03_Exponential_Approximations.html">4.3. Exponential Approximations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/04_The_Poisson_Distribution.html">4.4. The Poisson Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/05_Exercises.html">4.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_05/00_Expectation.html">5. Expectation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/01_Definition.html">5.1. Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/02_Functions_of_Random_Variables.html">5.2. Functions of Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/03_Method_of_Indicators.html">5.3. Method of Indicators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/04_Unbiased_Estimators.html">5.4. Unbiased Estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/05_Conditional_Expectation.html">5.5. Conditional Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/06_Expectation_by_Conditioning.html">5.6. Expectation by Conditioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/07_Exercises.html">5.7. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_06/00_Measuring_Variability.html">6. Measuring Variability</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/01_Variance_and_Standard_Deviation.html">6.1. Variance and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/02_Simplifying_the_Calculation.html">6.2. Simplifying the Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/03_Markovs_Inequality.html">6.3. Markov’s Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/04_Chebyshevs_Inequality.html">6.4. Chebyshev’s Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/05_Exercises.html">6.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_07/00_The_Variance_of_a_Sum.html">7. The Variance of a Sum</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_07/01_Sums_of_Independent_Random_Variables.html">7.1. Sums of Independent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_07/02_Sampling_Without_Replacement.html">7.2. Sampling Without Replacement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_07/03_The_Law_of_Averages.html">7.3. The Law of Averages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_07/04_Exercises.html">7.4. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_08/00_Central_Limit_Theorem.html">8. Central Limit Theorem</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/01_Distribution_of_a_Sample_Sum.html">8.1. The Distribution of a Sample Sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/02_Standard_Normal_Curve.html">8.2. Standard Normal Curve</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/03_Normal_Approximation.html">8.3. Normal Approximation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/04_How_Large_is_Large.html">8.4. How Large is “Large”?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/05_Exercises.html">8.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_09/00_Inference.html">9. Inference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/01_Confidence_Intervals_Method.html">9.1. Confidence Intervals: Method</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/02_Confidence_Intervals_Interpretation.html">9.2. Confidence Intervals: Interpretation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/03_Testing_Hypotheses.html">9.3. Testing Hypotheses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/04_AB_Testing_Fishers_Exact_Test.html">9.4. A/B Testing: Fisher’s Exact Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/05_Exercises.html">9.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_10/00_Probability_Density.html">10. Probability Density</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/01_Density.html">10.1. Density</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/02_Expectation_and_Variance.html">10.2. Expectation and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/03_The_Exponential_Distribution.html">10.3. Exponential Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/04_The_Normal_Distribution.html">10.4. The Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/05_Exercises.html">10.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_11/00_Bias_Variance_and_Least_Squares.html">11. Bias, Variance, and Least Squares</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/01_Bias_and_Variance.html">11.1. Bias and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/02_Examples.html">11.2. Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/03_Least_Squares_Linear_Regression.html">11.3. Least Squares Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/04_Bounds_on_Correlation.html">11.4. Bounds on Correlation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/05_The_Error_in_Regression.html">11.5. The Error in Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/06_Exercises.html">11.6. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="00_Inference_in_Regression.html">12. Inference in Regression</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_The_Simple_Linear_Regression_Model.html">12.1. The Simple Linear Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_The_Distribution_of_the_Estimated_Slope.html">12.2. The Distribution of the Estimated Slope</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">12.3. Towards Multiple Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_Exercises.html">12.4. Exercises</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/content/Chapter_12/03_Towards_Multiple_Regression.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Towards Multiple Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression">12.3.1. Multiple Regression</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="cell tag_remove_input docutils container">
</div>
<section id="towards-multiple-regression">
<h1><span class="section-number">12.3. </span>Towards Multiple Regression<a class="headerlink" href="#towards-multiple-regression" title="Link to this heading">#</a></h1>
<p>This section is an extended example of applications of the methods we have derived for regression. We will start with simple regression, which we understand well, and will then indicate how some of the results can be extended when there is more than one predictor variable.</p>
<p>The data are from a study on the treatment of Hodgkin’s disease, a type of cancer that can affect young people. The good news is that treatments for this cancer have <a class="reference external" href="https://en.wikipedia.org/wiki/Hodgkin_lymphoma#Prognosis">high success rates</a>. The bad news is that the treatments can be rather strong combinations of chemotherapy and radiation, and thus have serious side effects. A goal of the study was to identify combinations of treatments with reduced side effects.</p>
<p>The table <code class="docutils literal notranslate"><span class="pre">hodgkins</span></code> contains data on a random sample of patients. Each row corresponds to a patient. The columns contain the patient’s height in centimeters, the amount of radiation, the amount of medication used in chemotherapy, and measurements on the health of the patient’s lungs.</p>
<div class="cell tag_remove_input docutils container">
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hodgkins</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table border="1" class="dataframe">
    <thead>
        <tr>
            <th>height</th> <th>rad</th> <th>chemo</th> <th>base</th> <th>month15</th> <th>difference</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>164   </td> <td>679 </td> <td>180  </td> <td>160.57</td> <td>87.77  </td> <td>-72.8     </td>
        </tr>
        <tr>
            <td>168   </td> <td>311 </td> <td>180  </td> <td>98.24 </td> <td>67.62  </td> <td>-30.62    </td>
        </tr>
        <tr>
            <td>173   </td> <td>388 </td> <td>239  </td> <td>129.04</td> <td>133.33 </td> <td>4.29      </td>
        </tr>
        <tr>
            <td>157   </td> <td>370 </td> <td>168  </td> <td>85.41 </td> <td>81.28  </td> <td>-4.13     </td>
        </tr>
        <tr>
            <td>160   </td> <td>468 </td> <td>151  </td> <td>67.94 </td> <td>79.26  </td> <td>11.32     </td>
        </tr>
        <tr>
            <td>170   </td> <td>341 </td> <td>96   </td> <td>150.51</td> <td>80.97  </td> <td>-69.54    </td>
        </tr>
        <tr>
            <td>163   </td> <td>453 </td> <td>134  </td> <td>129.88</td> <td>69.24  </td> <td>-60.64    </td>
        </tr>
        <tr>
            <td>175   </td> <td>529 </td> <td>264  </td> <td>87.45 </td> <td>56.48  </td> <td>-30.97    </td>
        </tr>
        <tr>
            <td>185   </td> <td>392 </td> <td>240  </td> <td>149.84</td> <td>106.99 </td> <td>-42.85    </td>
        </tr>
        <tr>
            <td>178   </td> <td>479 </td> <td>216  </td> <td>92.24 </td> <td>73.43  </td> <td>-18.81    </td>
        </tr>
    </tbody>
</table>
<p>... (12 rows omitted)</p></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="n">hodgkins</span><span class="o">.</span><span class="n">num_rows</span>
<span class="n">n</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>22
</pre></div>
</div>
</div>
</div>
<p>The radiation was directed towards each patient’s chest area or “mantle”, to destroy cancer cells in the lymph nodes near that area. Since this could adversely affect the patients’ lungs, the researchers measured the health of the patients’ lungs both before and after treatment. Each patient received a score, with larger scores corresponding to more healthy lungs.</p>
<p>The table records the baseline scores and also the scores 15 months after treatment. The change in score (15 month score minus baseline score) is in the final column. Notice the negative differences: 15 months after treatment, many patients’ lungs weren’t doing as well as before the treatment.</p>
<p>Perhaps not surprisingly, patients with larger baseline scores had bigger drops in score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hodgkins</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;base&#39;</span><span class="p">,</span> <span class="s1">&#39;difference&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/0040f936438909c9a87d3ad84f66ac8f78e98c707821f034ce93e5cabd560527.png" src="../../_images/0040f936438909c9a87d3ad84f66ac8f78e98c707821f034ce93e5cabd560527.png" />
</div>
</div>
<p>We will regress the difference on the baseline score, this time using the Python module <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> that allows us to easily perform multiple regression as well. You don’t have to learn the code below (though it’s not hard). Just focus on understanding an interpreting the output.</p>
<p>As a first step, we must import the module.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sm</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">Table</span></code> method <code class="docutils literal notranslate"><span class="pre">to_df</span></code> allows us to convert the table <code class="docutils literal notranslate"><span class="pre">hodgkins</span></code> to a structure called a data frame that works more smoothly with <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h_data</span> <span class="o">=</span> <span class="n">hodgkins</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span>
<span class="n">h_data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height</th>
      <th>rad</th>
      <th>chemo</th>
      <th>base</th>
      <th>month15</th>
      <th>difference</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>164</td>
      <td>679</td>
      <td>180</td>
      <td>160.57</td>
      <td>87.77</td>
      <td>-72.80</td>
    </tr>
    <tr>
      <th>1</th>
      <td>168</td>
      <td>311</td>
      <td>180</td>
      <td>98.24</td>
      <td>67.62</td>
      <td>-30.62</td>
    </tr>
    <tr>
      <th>2</th>
      <td>173</td>
      <td>388</td>
      <td>239</td>
      <td>129.04</td>
      <td>133.33</td>
      <td>4.29</td>
    </tr>
    <tr>
      <th>3</th>
      <td>157</td>
      <td>370</td>
      <td>168</td>
      <td>85.41</td>
      <td>81.28</td>
      <td>-4.13</td>
    </tr>
    <tr>
      <th>4</th>
      <td>160</td>
      <td>468</td>
      <td>151</td>
      <td>67.94</td>
      <td>79.26</td>
      <td>11.32</td>
    </tr>
    <tr>
      <th>5</th>
      <td>170</td>
      <td>341</td>
      <td>96</td>
      <td>150.51</td>
      <td>80.97</td>
      <td>-69.54</td>
    </tr>
    <tr>
      <th>6</th>
      <td>163</td>
      <td>453</td>
      <td>134</td>
      <td>129.88</td>
      <td>69.24</td>
      <td>-60.64</td>
    </tr>
    <tr>
      <th>7</th>
      <td>175</td>
      <td>529</td>
      <td>264</td>
      <td>87.45</td>
      <td>56.48</td>
      <td>-30.97</td>
    </tr>
    <tr>
      <th>8</th>
      <td>185</td>
      <td>392</td>
      <td>240</td>
      <td>149.84</td>
      <td>106.99</td>
      <td>-42.85</td>
    </tr>
    <tr>
      <th>9</th>
      <td>178</td>
      <td>479</td>
      <td>216</td>
      <td>92.24</td>
      <td>73.43</td>
      <td>-18.81</td>
    </tr>
    <tr>
      <th>10</th>
      <td>179</td>
      <td>376</td>
      <td>160</td>
      <td>117.43</td>
      <td>101.61</td>
      <td>-15.82</td>
    </tr>
    <tr>
      <th>11</th>
      <td>181</td>
      <td>539</td>
      <td>196</td>
      <td>129.75</td>
      <td>90.78</td>
      <td>-38.97</td>
    </tr>
    <tr>
      <th>12</th>
      <td>173</td>
      <td>217</td>
      <td>204</td>
      <td>97.59</td>
      <td>76.38</td>
      <td>-21.21</td>
    </tr>
    <tr>
      <th>13</th>
      <td>166</td>
      <td>456</td>
      <td>192</td>
      <td>81.29</td>
      <td>67.66</td>
      <td>-13.63</td>
    </tr>
    <tr>
      <th>14</th>
      <td>170</td>
      <td>252</td>
      <td>150</td>
      <td>98.29</td>
      <td>55.51</td>
      <td>-42.78</td>
    </tr>
    <tr>
      <th>15</th>
      <td>165</td>
      <td>622</td>
      <td>162</td>
      <td>118.98</td>
      <td>90.92</td>
      <td>-28.06</td>
    </tr>
    <tr>
      <th>16</th>
      <td>173</td>
      <td>305</td>
      <td>213</td>
      <td>103.17</td>
      <td>79.74</td>
      <td>-23.43</td>
    </tr>
    <tr>
      <th>17</th>
      <td>174</td>
      <td>566</td>
      <td>198</td>
      <td>94.97</td>
      <td>93.08</td>
      <td>-1.89</td>
    </tr>
    <tr>
      <th>18</th>
      <td>173</td>
      <td>322</td>
      <td>119</td>
      <td>85.00</td>
      <td>41.96</td>
      <td>-43.04</td>
    </tr>
    <tr>
      <th>19</th>
      <td>173</td>
      <td>270</td>
      <td>160</td>
      <td>115.02</td>
      <td>81.12</td>
      <td>-33.90</td>
    </tr>
    <tr>
      <th>20</th>
      <td>183</td>
      <td>259</td>
      <td>241</td>
      <td>125.02</td>
      <td>97.18</td>
      <td>-27.84</td>
    </tr>
    <tr>
      <th>21</th>
      <td>188</td>
      <td>238</td>
      <td>252</td>
      <td>137.43</td>
      <td>113.20</td>
      <td>-24.23</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>There are several variables we could use to predict the difference. The only one we wouldn’t use is the 15 month measurement, as that’s precisely what we won’t have for a new patient before the treatment is adminstered.</p>
<p>But which of the rest should we use? One way to choose is to look at the <em>correlation matrix</em> of all the variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h_data</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height</th>
      <th>rad</th>
      <th>chemo</th>
      <th>base</th>
      <th>month15</th>
      <th>difference</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>height</th>
      <td>1.000000</td>
      <td>-0.305206</td>
      <td>0.576825</td>
      <td>0.354229</td>
      <td>0.390527</td>
      <td>-0.043394</td>
    </tr>
    <tr>
      <th>rad</th>
      <td>-0.305206</td>
      <td>1.000000</td>
      <td>-0.003739</td>
      <td>0.096432</td>
      <td>0.040616</td>
      <td>-0.073453</td>
    </tr>
    <tr>
      <th>chemo</th>
      <td>0.576825</td>
      <td>-0.003739</td>
      <td>1.000000</td>
      <td>0.062187</td>
      <td>0.445788</td>
      <td>0.346310</td>
    </tr>
    <tr>
      <th>base</th>
      <td>0.354229</td>
      <td>0.096432</td>
      <td>0.062187</td>
      <td>1.000000</td>
      <td>0.561371</td>
      <td>-0.630183</td>
    </tr>
    <tr>
      <th>month15</th>
      <td>0.390527</td>
      <td>0.040616</td>
      <td>0.445788</td>
      <td>0.561371</td>
      <td>1.000000</td>
      <td>0.288794</td>
    </tr>
    <tr>
      <th>difference</th>
      <td>-0.043394</td>
      <td>-0.073453</td>
      <td>0.346310</td>
      <td>-0.630183</td>
      <td>0.288794</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Each entry in this table is the correlation between the variable specified by the row label and the variable specified by the column label. That’s why all the diagonal entries are <span class="math notranslate nohighlight">\(1\)</span>.</p>
<p>Look at the last column (or last row). This contains the correlation between <code class="docutils literal notranslate"><span class="pre">difference</span></code> and each of the other variables. The baseline measurement has the largest correlation. To run the regression of <code class="docutils literal notranslate"><span class="pre">difference</span></code> on <code class="docutils literal notranslate"><span class="pre">base</span></code> we must first extract the columns of data that we need and then use the appropriate <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> methods.</p>
<p>First, we create data frames corresponding to the response and the predictor variable. The methods are not the same as for <code class="docutils literal notranslate"><span class="pre">Tables</span></code>, but you will get a general sense of what they are doing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">h_data</span><span class="p">[[</span><span class="s1">&#39;difference&#39;</span><span class="p">]]</span>  <span class="c1"># response</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">h_data</span><span class="p">[[</span><span class="s1">&#39;base&#39;</span><span class="p">]]</span>        <span class="c1"># predictor</span>

<span class="c1"># specify that the model includes an intercept</span>
<span class="n">x_with_int</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<p>The name of the <code class="docutils literal notranslate"><span class="pre">OLS</span></code> method stands for Ordinary Least Squares, which is the kind of least squares that we have discussed. There are other more complicated kinds that you might encounter in more advanced classes.</p>
<p>There is a lot of output, some of which we will discuss and the rest of which we will leave to another class. For some reason the output includes the date and time of running the regression, right in the middle of the summary statistics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simple_regression</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x_with_int</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">simple_regression</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>difference</td>    <th>  R-squared:         </th> <td>   0.397</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.367</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.17</td>
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 13 Mar 2025</td> <th>  Prob (F-statistic):</th>  <td>0.00167</td>
</tr>
<tr>
  <th>Time:</th>                 <td>14:22:25</td>     <th>  Log-Likelihood:    </th> <td> -92.947</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    22</td>      <th>  AIC:               </th> <td>   189.9</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    20</td>      <th>  BIC:               </th> <td>   192.1</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th> <td>   32.1721</td> <td>   17.151</td> <td>    1.876</td> <td> 0.075</td> <td>   -3.604</td> <td>   67.949</td>
</tr>
<tr>
  <th>base</th>  <td>   -0.5447</td> <td>    0.150</td> <td>   -3.630</td> <td> 0.002</td> <td>   -0.858</td> <td>   -0.232</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 1.133</td> <th>  Durbin-Watson:     </th> <td>   1.774</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.568</td> <th>  Jarque-Bera (JB):  </th> <td>   0.484</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.362</td> <th>  Prob(JB):          </th> <td>   0.785</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.069</td> <th>  Cond. No.          </th> <td>    530.</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>There are three blocks of output. We will focus only on the the middle block.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">const</span></code> and <code class="docutils literal notranslate"><span class="pre">base</span></code> refer to the intercept and baseline measurement.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">coef</span></code> stands for the estimated coefficients, which in our notation are <span class="math notranslate nohighlight">\(\hat{\beta_0}\)</span> and <span class="math notranslate nohighlight">\(\hat{\beta_1}\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">t</span></code> is the <span class="math notranslate nohighlight">\(t\)</span>-statistic for testing whether or not the coefficient is 0. Based on our model, its degrees of freedom are <span class="math notranslate nohighlight">\(n-2 = 20\)</span>; you’ll find this under <code class="docutils literal notranslate"><span class="pre">Df</span> <span class="pre">Residuals</span></code> in the top block.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">P</span> <span class="pre">&gt;</span> <span class="pre">|t|</span></code> is the total area in the two tails of the <span class="math notranslate nohighlight">\(t\)</span> distribution with <span class="math notranslate nohighlight">\(n-2\)</span> degrees of freedom.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[0.025</span> <span class="pre">0.975]</span></code> are the ends of a 95% confidence interval for the parameter.</p></li>
</ul>
<p>For the test of whether or not the true slope of the baseline measurement is <span class="math notranslate nohighlight">\(0\)</span>, the observed test statistic is</p>
<div class="math notranslate nohighlight">
\[
\frac{-0.5447 - 0}{0.150} ~ = ~ -3.63
\]</div>
<p>The area in one tail is the chance that the <span class="math notranslate nohighlight">\(t\)</span> distribution with <span class="math notranslate nohighlight">\(20\)</span> degrees of freedom is less than <span class="math notranslate nohighlight">\(-3.63\)</span>. That’s the cdf of the distribution evaluated at <span class="math notranslate nohighlight">\(-3.63\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">one_tail</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="o">-</span><span class="mf">3.63</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">one_tail</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.00083395814096297143
</pre></div>
</div>
</div>
</div>
<p>Our test is two-sided (large values of <span class="math notranslate nohighlight">\(\vert t \vert\)</span> favor the alternative), so the <span class="math notranslate nohighlight">\(p\)</span>-value of the test is the total area of two tails, which is the displayed value <span class="math notranslate nohighlight">\(0.002\)</span> after rounding.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">one_tail</span>
<span class="n">p</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0016679162819259429
</pre></div>
</div>
</div>
</div>
<p>To find a 95% confidence interval for the true slope, we have to replace <span class="math notranslate nohighlight">\(2\)</span> in the expression <span class="math notranslate nohighlight">\(\hat{\beta}_1 \pm 2SE(\hat{\beta}_1)\)</span> by the corresponding value from the <span class="math notranslate nohighlight">\(t\)</span> distribution with 20 degrees of freedom. That’s not very far from <span class="math notranslate nohighlight">\(2\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t_95</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">t_95</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.0859634472658368
</pre></div>
</div>
</div>
</div>
<p>A 95% confidence interval for the true slope is given by <span class="math notranslate nohighlight">\(\hat{\beta}_1 \pm t_{95}SE(\hat{\beta}_1)\)</span>. The observed interval is therefore given by the calculation below, which results in the same values as in the output of <code class="docutils literal notranslate"><span class="pre">sm.OLS</span></code> above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 95% confidence interval for the true slope</span>

<span class="o">-</span><span class="mf">0.5447</span> <span class="o">-</span> <span class="n">t_95</span><span class="o">*</span><span class="mf">0.150</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5447</span> <span class="o">+</span> <span class="n">t_95</span><span class="o">*</span><span class="mf">0.150</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(-0.85759451708987555, -0.23180548291012443)
</pre></div>
</div>
</div>
</div>
<section id="multiple-regression">
<h2><span class="section-number">12.3.1. </span>Multiple Regression<a class="headerlink" href="#multiple-regression" title="Link to this heading">#</a></h2>
<p>What if we wanted to regress <code class="docutils literal notranslate"><span class="pre">difference</span></code> on both <code class="docutils literal notranslate"><span class="pre">base</span></code> and <code class="docutils literal notranslate"><span class="pre">chemo</span></code>? The first thing to do would be to check the correlation matrix again:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h_data</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height</th>
      <th>rad</th>
      <th>chemo</th>
      <th>base</th>
      <th>month15</th>
      <th>difference</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>height</th>
      <td>1.000000</td>
      <td>-0.305206</td>
      <td>0.576825</td>
      <td>0.354229</td>
      <td>0.390527</td>
      <td>-0.043394</td>
    </tr>
    <tr>
      <th>rad</th>
      <td>-0.305206</td>
      <td>1.000000</td>
      <td>-0.003739</td>
      <td>0.096432</td>
      <td>0.040616</td>
      <td>-0.073453</td>
    </tr>
    <tr>
      <th>chemo</th>
      <td>0.576825</td>
      <td>-0.003739</td>
      <td>1.000000</td>
      <td>0.062187</td>
      <td>0.445788</td>
      <td>0.346310</td>
    </tr>
    <tr>
      <th>base</th>
      <td>0.354229</td>
      <td>0.096432</td>
      <td>0.062187</td>
      <td>1.000000</td>
      <td>0.561371</td>
      <td>-0.630183</td>
    </tr>
    <tr>
      <th>month15</th>
      <td>0.390527</td>
      <td>0.040616</td>
      <td>0.445788</td>
      <td>0.561371</td>
      <td>1.000000</td>
      <td>0.288794</td>
    </tr>
    <tr>
      <th>difference</th>
      <td>-0.043394</td>
      <td>-0.073453</td>
      <td>0.346310</td>
      <td>-0.630183</td>
      <td>0.288794</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>What you are looking for is not just that <code class="docutils literal notranslate"><span class="pre">chemo</span></code> is the next most highly correlated with <code class="docutils literal notranslate"><span class="pre">difference</span></code> after <code class="docutils literal notranslate"><span class="pre">base</span></code>. More importantly, you are looking to see how strongly the two predictor variables <code class="docutils literal notranslate"><span class="pre">base</span></code> and <code class="docutils literal notranslate"><span class="pre">chemo</span></code> are linearly related <em>to each other</em>. That is, you are trying to figure out whether the two variables pick up genuinely different dimensions of the data.</p>
<p>The correlation matrix shows that the correlation between <code class="docutils literal notranslate"><span class="pre">base</span></code> and <code class="docutils literal notranslate"><span class="pre">chemo</span></code> is only about <span class="math notranslate nohighlight">\(0.06\)</span>. The two predictors are not close to being linear functions of each other. So let’s run the regression.</p>
<p>The code is exactly the same as before, except that we have included a second predictor variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">h_data</span><span class="p">[[</span><span class="s1">&#39;difference&#39;</span><span class="p">]]</span>      <span class="c1"># response</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">h_data</span><span class="p">[[</span><span class="s1">&#39;base&#39;</span><span class="p">,</span> <span class="s1">&#39;chemo&#39;</span><span class="p">]]</span>  <span class="c1"># predictors</span>

<span class="c1"># specify that the model includes an intercept</span>
<span class="n">x2_with_int</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span> 

<span class="n">multiple_regression</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x2_with_int</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">multiple_regression</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>difference</td>    <th>  R-squared:         </th> <td>   0.546</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.499</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.44</td>
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 13 Mar 2025</td> <th>  Prob (F-statistic):</th> <td>0.000548</td>
</tr>
<tr>
  <th>Time:</th>                 <td>14:22:25</td>     <th>  Log-Likelihood:    </th> <td> -89.820</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    22</td>      <th>  AIC:               </th> <td>   185.6</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    19</td>      <th>  BIC:               </th> <td>   188.9</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th> <td>   -0.9992</td> <td>   20.227</td> <td>   -0.049</td> <td> 0.961</td> <td>  -43.335</td> <td>   41.336</td>
</tr>
<tr>
  <th>base</th>  <td>   -0.5655</td> <td>    0.134</td> <td>   -4.226</td> <td> 0.000</td> <td>   -0.846</td> <td>   -0.285</td>
</tr>
<tr>
  <th>chemo</th> <td>    0.1898</td> <td>    0.076</td> <td>    2.500</td> <td> 0.022</td> <td>    0.031</td> <td>    0.349</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.853</td> <th>  Durbin-Watson:     </th> <td>   1.781</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.653</td> <th>  Jarque-Bera (JB):  </th> <td>   0.368</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.317</td> <th>  Prob(JB):          </th> <td>   0.832</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.987</td> <th>  Cond. No.          </th> <td>1.36e+03</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.36e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.</div></div>
</div>
<p>Ignore the scary warning above. There isn’t strong multicollinearity (predictor variables being highly correlated with each other) nor other serious issues.</p>
<p>Just focus on the middle block of the output. It’s just like the middle block of the simple regression output, with one more line corresponding to <code class="docutils literal notranslate"><span class="pre">chemo</span></code>.</p>
<p>All of the values in the block are interpreted in the same way as before. The only change is in the degrees of freedom: because you are estimating one more parameter, the degrees of freedom have dropped by <span class="math notranslate nohighlight">\(1\)</span>, and are thus <span class="math notranslate nohighlight">\(19\)</span> instead of <span class="math notranslate nohighlight">\(20\)</span>.</p>
<p>For example, the 95% confidence interval for the slope of <code class="docutils literal notranslate"><span class="pre">chemo</span></code> is calculated as follows.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t_95_df19</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">,</span> <span class="mi">19</span><span class="p">)</span>

<span class="mf">0.1898</span> <span class="o">-</span> <span class="n">t_95_df19</span><span class="o">*</span><span class="mf">0.076</span><span class="p">,</span> <span class="mf">0.1898</span> <span class="o">+</span> <span class="n">t_95_df19</span><span class="o">*</span><span class="mf">0.076</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.030730171864972011, 0.34886982813502798)
</pre></div>
</div>
</div>
</div>
<p>Finally, take a look at the value of <code class="docutils literal notranslate"><span class="pre">R-squared</span></code> in the very top line. It is <span class="math notranslate nohighlight">\(0.546\)</span> compared to <span class="math notranslate nohighlight">\(0.397\)</span> for the simple regression. It’s a math fact that the more predictor variables you use, the higher the <code class="docutils literal notranslate"><span class="pre">R-squared</span></code> value will be. This tempts people into using lots of predictors, whether or not the resulting model is comprehensible.</p>
<p>With an “everything as well as the kitchen sink” approach to selecting predictor variables, a researcher might be inclined to use all the possible predictors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">h_data</span><span class="p">[[</span><span class="s1">&#39;difference&#39;</span><span class="p">]]</span>      <span class="c1"># response</span>
<span class="n">x3</span> <span class="o">=</span> <span class="n">h_data</span><span class="p">[[</span><span class="s1">&#39;base&#39;</span><span class="p">,</span> <span class="s1">&#39;chemo&#39;</span><span class="p">,</span> <span class="s1">&#39;rad&#39;</span><span class="p">,</span> <span class="s1">&#39;height&#39;</span><span class="p">]]</span>  <span class="c1"># predictors</span>

<span class="c1"># specify that the model includes an intercept</span>
<span class="n">x3_with_int</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span> 

<span class="n">bad_regression</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x3_with_int</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">bad_regression</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>difference</td>    <th>  R-squared:         </th> <td>   0.550</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.444</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.185</td>
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 13 Mar 2025</td> <th>  Prob (F-statistic):</th>  <td>0.00645</td>
</tr>
<tr>
  <th>Time:</th>                 <td>14:22:25</td>     <th>  Log-Likelihood:    </th> <td> -89.741</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    22</td>      <th>  AIC:               </th> <td>   189.5</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    17</td>      <th>  BIC:               </th> <td>   194.9</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th>  <td>   33.5226</td> <td>  101.061</td> <td>    0.332</td> <td> 0.744</td> <td> -179.698</td> <td>  246.743</td>
</tr>
<tr>
  <th>base</th>   <td>   -0.5393</td> <td>    0.160</td> <td>   -3.378</td> <td> 0.004</td> <td>   -0.876</td> <td>   -0.202</td>
</tr>
<tr>
  <th>chemo</th>  <td>    0.2124</td> <td>    0.103</td> <td>    2.053</td> <td> 0.056</td> <td>   -0.006</td> <td>    0.431</td>
</tr>
<tr>
  <th>rad</th>    <td>   -0.0062</td> <td>    0.031</td> <td>   -0.203</td> <td> 0.841</td> <td>   -0.071</td> <td>    0.059</td>
</tr>
<tr>
  <th>height</th> <td>   -0.2274</td> <td>    0.658</td> <td>   -0.346</td> <td> 0.734</td> <td>   -1.615</td> <td>    1.160</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.589</td> <th>  Durbin-Watson:     </th> <td>   1.812</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.745</td> <th>  Jarque-Bera (JB):  </th> <td>   0.321</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.286</td> <th>  Prob(JB):          </th> <td>   0.852</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.851</td> <th>  Cond. No.          </th> <td>1.46e+04</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.46e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems.</div></div>
</div>
<p>This is not a good idea. We end up with a far more complicated model for no appreciable gain in <code class="docutils literal notranslate"><span class="pre">R-squared</span></code>. The “adjusted <span class="math notranslate nohighlight">\(R^2\)</span>” penalizes us for using more predictor variables: notice that the value of <code class="docutils literal notranslate"><span class="pre">Adj.</span> <span class="pre">R-squared</span></code> is smaller for the regression with all the predictors than for the regression with just <code class="docutils literal notranslate"><span class="pre">base</span></code> and <code class="docutils literal notranslate"><span class="pre">chemo</span></code>.</p>
<p>Curious about how to select predictors, or about what makes a good regression? Then take some more statistics classes! This one is complete.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/Chapter_12"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="02_The_Distribution_of_the_Estimated_Slope.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">12.2. </span>The Distribution of the Estimated Slope</p>
      </div>
    </a>
    <a class="right-next"
       href="04_Exercises.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">12.4. </span>Exercises</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression">12.3.1. Multiple Regression</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ani Adhikari
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>