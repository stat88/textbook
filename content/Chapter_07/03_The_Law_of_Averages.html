
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>7.3. The Law of Averages &#8212; Data 88S Textbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/Chapter_07/03_The_Law_of_Averages';</script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="7.4. Exercises" href="04_Exercises.html" />
    <link rel="prev" title="7.2. Sampling Without Replacement" href="02_Sampling_Without_Replacement.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/data88s_logo.png" class="logo__image only-light" alt="Data 88S Textbook - Home"/>
    <script>document.write(`<img src="../../_static/data88s_logo.png" class="logo__image only-dark" alt="Data 88S Textbook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="http://stat88.org">Course Home</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_01/00_The_Basics.html">1. The Basics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/01_Probabilities_as_Proportions.html">1.1. Probabilities as Proportions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/02_Exact_Calculation_or_Bound.html">1.2. Exact Calculation, or Bound?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/03_Fundamental_Rules.html">1.3. Fundamental Rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/04_Exercises.html">1.4. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_02/00_Intersections_and_Conditioning.html">2. Intersections and Conditioning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/01_The_Chance_of_an_Intersection.html">2.1. The Chance of an Intersection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/02_Symmetry_in_Simple_Random_Sampling.html">2.2. Symmetry in Simple Random Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/03_Bayes_Rule.html">2.3. Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/04_Use_and_Interpretation.html">2.4. Use and Interpretation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/05_Independence.html">2.5. Independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/06_Exercises.html">2.6. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_03/00_Random_Counts.html">3. Random Counts</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/01_Success_and_Failure.html">3.1. Success and Failure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/02_Random_Variables.html">3.2. Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/03_The_Binomial_Distribution.html">3.3. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/04_The_Hypergeometric_Distribution.html">3.4. The Hypergeometric Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/05_Examples.html">3.5. Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/06_Exercises.html">3.6. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_04/00_Infinitely_Many_Values.html">4. Infinitely Many Values</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/01_Cumulative_Distribution_Function.html">4.1. Cumulative Distribution Function (CDF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/02_Waiting_Times.html">4.2. Waiting Times</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/03_Exponential_Approximations.html">4.3. Exponential Approximations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/04_The_Poisson_Distribution.html">4.4. The Poisson Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/05_Exercises.html">4.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_05/00_Expectation.html">5. Expectation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/01_Definition.html">5.1. Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/02_Functions_of_Random_Variables.html">5.2. Functions of Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/03_Method_of_Indicators.html">5.3. Method of Indicators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/04_Unbiased_Estimators.html">5.4. Unbiased Estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/05_Conditional_Expectation.html">5.5. Conditional Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/06_Expectation_by_Conditioning.html">5.6. Expectation by Conditioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/07_Exercises.html">5.7. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_06/00_Measuring_Variability.html">6. Measuring Variability</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/01_Variance_and_Standard_Deviation.html">6.1. Variance and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/02_Simplifying_the_Calculation.html">6.2. Simplifying the Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/03_Markovs_Inequality.html">6.3. Markov’s Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/04_Chebyshevs_Inequality.html">6.4. Chebyshev’s Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/05_Exercises.html">6.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="00_The_Variance_of_a_Sum.html">7. The Variance of a Sum</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_Sums_of_Independent_Random_Variables.html">7.1. Sums of Independent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_Sampling_Without_Replacement.html">7.2. Sampling Without Replacement</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">7.3. The Law of Averages</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_Exercises.html">7.4. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_08/00_Central_Limit_Theorem.html">8. Central Limit Theorem</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/01_Distribution_of_a_Sample_Sum.html">8.1. The Distribution of a Sample Sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/02_Standard_Normal_Curve.html">8.2. Standard Normal Curve</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/03_Normal_Approximation.html">8.3. Normal Approximation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/04_How_Large_is_Large.html">8.4. How Large is “Large”?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/05_Exercises.html">8.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_09/00_Inference.html">9. Inference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/01_Confidence_Intervals_Method.html">9.1. Confidence Intervals: Method</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/02_Confidence_Intervals_Interpretation.html">9.2. Confidence Intervals: Interpretation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/03_Testing_Hypotheses.html">9.3. Testing Hypotheses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/04_AB_Testing_Fishers_Exact_Test.html">9.4. A/B Testing: Fisher’s Exact Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/05_Exercises.html">9.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_10/00_Probability_Density.html">10. Probability Density</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/01_Density.html">10.1. Density</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/02_Expectation_and_Variance.html">10.2. Expectation and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/03_The_Exponential_Distribution.html">10.3. Exponential Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/04_The_Normal_Distribution.html">10.4. The Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/05_Exercises.html">10.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_11/00_Bias_Variance_and_Least_Squares.html">11. Bias, Variance, and Least Squares</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/01_Bias_and_Variance.html">11.1. Bias and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/02_Examples.html">11.2. Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/03_Least_Squares_Linear_Regression.html">11.3. Least Squares Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/04_Bounds_on_Correlation.html">11.4. Bounds on Correlation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/05_The_Error_in_Regression.html">11.5. The Error in Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/06_Exercises.html">11.6. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_12/00_Inference_in_Regression.html">12. Inference in Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_12/01_The_Simple_Linear_Regression_Model.html">12.1. The Simple Linear Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_12/02_The_Distribution_of_the_Estimated_Slope.html">12.2. The Distribution of the Estimated Slope</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_12/03_Towards_Multiple_Regression.html">12.3. Towards Multiple Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_12/04_Exercises.html">12.4. Exercises</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/content/Chapter_07/03_The_Law_of_Averages.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The Law of Averages</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sample-sum">7.3.1. The Sample Sum</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exactly-half-heads">7.3.2. Exactly Half Heads</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sample-average">7.3.3. The Sample Average</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-square-root-law">7.3.4. The Square Root Law</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concentration-of-probabilities">7.3.5. Concentration of Probabilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">7.3.6. The Law of Averages</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="cell tag_remove_input docutils container">
</div>
<section id="the-law-of-averages">
<h1><span class="section-number">7.3. </span>The Law of Averages<a class="headerlink" href="#the-law-of-averages" title="Link to this heading">#</a></h1>
<p>Informally, the <em>law of averages</em> is the familiar statement that if you toss a coin many times you get about half heads and half tails.</p>
<p>The main reason for studying the law of averages is to begin to understand why large random samples are the basis for inference in data science. In this section we will take a close look at the informal statement of the law and try to make it more precise. In the process, we will confirm some intuition about probabilities and also come across a fact that may be surprising.</p>
<section id="the-sample-sum">
<h2><span class="section-number">7.3.1. </span>The Sample Sum<a class="headerlink" href="#the-sample-sum" title="Link to this heading">#</a></h2>
<p>Before we get to averages let’s take a look at sums. Let <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span> be i.i.d. with mean <span class="math notranslate nohighlight">\(\mu\)</span> and SD <span class="math notranslate nohighlight">\(\sigma\)</span>, and let <span class="math notranslate nohighlight">\(S_n = X_1 + X_2 + \ldots + X_n\)</span>.</p>
<p>Then <span class="math notranslate nohighlight">\(E(S_n) = n\mu\)</span>, as we have known for some time. As the sample size <span class="math notranslate nohighlight">\(n\)</span> gets larger, <span class="math notranslate nohighlight">\(E(S_n)\)</span> also gets larger. This tells us that the distribution of <span class="math notranslate nohighlight">\(S_n\)</span> places its mass further and further to the right as <span class="math notranslate nohighlight">\(n\)</span> increases.</p>
<p>We also know that <span class="math notranslate nohighlight">\(Var(S_n) = n\sigma^2\)</span> and hence <span class="math notranslate nohighlight">\(SD(S_n) = \sqrt{n}\sigma\)</span>. As <span class="math notranslate nohighlight">\(n\)</span> increases, the distribution of <span class="math notranslate nohighlight">\(S_n\)</span> is more widely dispersed around its mean.</p>
<p>To visualize these properties, let’s take <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span> to be the indicators of heads on successive tosses of a coin.</p>
<p>Then <span class="math notranslate nohighlight">\(S_n\)</span> is the number of heads in <span class="math notranslate nohighlight">\(n\)</span> tosses and has the binomial <span class="math notranslate nohighlight">\((n, 1/2)\)</span> distribution with expectation <span class="math notranslate nohighlight">\(n/2\)</span> and SD <span class="math notranslate nohighlight">\(\sqrt{n}(1/2)\)</span>.</p>
<p>The figure below shows the probability histograms of <span class="math notranslate nohighlight">\(S_{100}\)</span> and <span class="math notranslate nohighlight">\(S_{400}\)</span>. You can see that the distribution of <span class="math notranslate nohighlight">\(S_{400}\)</span> is wider and to the right of the distribution of <span class="math notranslate nohighlight">\(S_{100}\)</span>.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<img alt="../../_images/eeac155c851de08a0919a594a9066e1c45b87a591d1901e03f9247a60db005c7.png" src="../../_images/eeac155c851de08a0919a594a9066e1c45b87a591d1901e03f9247a60db005c7.png" />
</div>
</div>
<p>Because the distribution of <span class="math notranslate nohighlight">\(S_{400}\)</span> is wider and the areas of both the histograms are 1, the histogram of <span class="math notranslate nohighlight">\(S_{400}\)</span> is lower than that of <span class="math notranslate nohighlight">\(S_{100}\)</span>. As the sample size <span class="math notranslate nohighlight">\(n\)</span> gets larger, the distribution of the sample sum shifts to the right and gets lower and more spread out.</p>
<p>This observation raises an interesting question. The histograms above indicate that the chance of 200 heads in 400 tosses is <em>less</em> than the chance of 50 heads in 100 tosses. Is that right? If so, how can it be consistent with the law of averages?</p>
<p>Let us try to answer these questions.</p>
</section>
<section id="exactly-half-heads">
<h2><span class="section-number">7.3.2. </span>Exactly Half Heads<a class="headerlink" href="#exactly-half-heads" title="Link to this heading">#</a></h2>
<p>The chance of exactly half heads is the chance of <span class="math notranslate nohighlight">\(n\)</span> heads in <span class="math notranslate nohighlight">\(2n\)</span> tosses, which we can calculate using the binomial formula.</p>
<div class="math notranslate nohighlight">
\[
P(n \text{ heads in } 2n \text{ tosses } ~ = ~ 
\binom{2n}{n}\left(\frac{1}{2}\right)^n\left(\frac{1}{2}\right)^n
\]</div>
<p>Here is a table of some of these values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">p_half_heads</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Assumes m is even and returns </span>
<span class="sd">    P(m/2 heads in m tosses)&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">m</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="n">even</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span><span class="s1">&#39;2n&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1001</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>
<span class="n">prob_half</span> <span class="o">=</span> <span class="n">even</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">p_half_heads</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">even</span> <span class="o">=</span> <span class="n">even</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span><span class="s1">&#39;P(n heads in 2n tosses)&#39;</span><span class="p">,</span> <span class="n">prob_half</span><span class="p">)</span>
<span class="n">even</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table border="1" class="dataframe">
    <thead>
        <tr>
            <th>2n</th> <th>P(n heads in 2n tosses)</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>100 </td> <td>0.0795892              </td>
        </tr>
        <tr>
            <td>150 </td> <td>0.0650385              </td>
        </tr>
        <tr>
            <td>200 </td> <td>0.0563485              </td>
        </tr>
        <tr>
            <td>250 </td> <td>0.0504122              </td>
        </tr>
        <tr>
            <td>300 </td> <td>0.0460275              </td>
        </tr>
        <tr>
            <td>350 </td> <td>0.0426183              </td>
        </tr>
        <tr>
            <td>400 </td> <td>0.0398693              </td>
        </tr>
        <tr>
            <td>450 </td> <td>0.0375917              </td>
        </tr>
        <tr>
            <td>500 </td> <td>0.0356646              </td>
        </tr>
        <tr>
            <td>550 </td> <td>0.0340065              </td>
        </tr>
    </tbody>
</table>
<p>... (9 rows omitted)</p></div></div>
</div>
<p>The first row tells us that the chance of 50 heads in 100 tosses is about 8%. The row corresponding to 400 tosses tells us that the chance of 200 heads in 400 tosses is about 4%. Both of these chances are consistent with the peaks of the histograms of <span class="math notranslate nohighlight">\(S_{100}\)</span> and <span class="math notranslate nohighlight">\(S_{400}\)</span>.</p>
<p>The entries in the chance column <em>decrease</em> as the number of tosses increases, ending at about 2.5% for the chance of 500 heads in 1000 tosses.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">even</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table border="1" class="dataframe">
    <thead>
        <tr>
            <th>2n</th> <th>P(n heads in 2n tosses)</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>1000</td> <td>0.025225               </td>
        </tr>
    </tbody>
</table></div></div>
</div>
<p>It is clear from these calculations that the chance of getting <em>exactly</em> half heads decreases as the number of tosses increases.</p>
<p>Indeed, it can be shown that the chance decreases to 0.</p>
<p>Why does this not contradict the law of averages? To understand this, look closely at the informal statment of the law: “If you toss a coin many times you get <em>about</em> half heads and half tails.”</p>
<p>The crucial word is <em>about</em>. You expect to get <em>about</em> half heads, not <em>exactly</em> half heads.</p>
<p>Now let’s try to understand “about” a bit better.</p>
</section>
<section id="the-sample-average">
<h2><span class="section-number">7.3.3. </span>The Sample Average<a class="headerlink" href="#the-sample-average" title="Link to this heading">#</a></h2>
<p>As before, let <span class="math notranslate nohighlight">\(S_n = X_1 + X_2 + \ldots + X_n\)</span> be the sum of i.i.d random variables that have mean <span class="math notranslate nohighlight">\(\mu\)</span> and SD <span class="math notranslate nohighlight">\(\sigma\)</span>. Now let <span class="math notranslate nohighlight">\(A_n = S_n / n\)</span> be the sample average.</p>
<p>When the <span class="math notranslate nohighlight">\(X_i\)</span>s are indicators, <span class="math notranslate nohighlight">\(A_n\)</span> is the sample proportion of successes.</p>
<p>But for the moment, we won’t specialize to indicators. Instead we will develop two general facts that are consequences of the linear relation <span class="math notranslate nohighlight">\(A_n = S_n/n\)</span>.</p>
<div class="math notranslate nohighlight">
\[
E(A_n) ~ = ~ \frac{1}{n}E(S_n) ~ = ~ \frac{1}{n} n\mu ~ = ~ \mu
\]</div>
<div class="math notranslate nohighlight">
\[
SD(A_n) ~ = ~ \frac{1}{n}SD(S_n) ~ = ~ \frac{1}{n}\sqrt{n}\sigma ~ = ~ \frac{\sigma}{\sqrt{n}}
\]</div>
<p>No matter what the sample size, the distribution of the sample mean balances at the population mean. As the sample size increases, the SD of the sample mean gets smaller.</p>
</section>
<section id="the-square-root-law">
<h2><span class="section-number">7.3.4. </span>The Square Root Law<a class="headerlink" href="#the-square-root-law" title="Link to this heading">#</a></h2>
<p>As you know, the sample mean <span class="math notranslate nohighlight">\(A_n\)</span> is an unbiased estimator of the population mean. In the language of estimation, the <em>accuracy</em> of an unbiased estimator can be measured by its SD: the smaller the SD, the more accurate the estimator.</p>
<p>Let’s compare <span class="math notranslate nohighlight">\(SD(A_{100})\)</span> and <span class="math notranslate nohighlight">\(SD(A_{400})\)</span>. We know that <span class="math notranslate nohighlight">\(SD(A_{400})\)</span> is smaller, but by how much?</p>
<div class="math notranslate nohighlight">
\[
SD(A_{400}) ~ = ~ \frac{\sigma}{\sqrt{400}} ~ = ~ \frac{\sigma}{\sqrt{4}\sqrt{100}} ~ = ~ \frac{1}{2}SD(A_{100})
\]</div>
<p>We say that <span class="math notranslate nohighlight">\(A_{400}\)</span> is <em>twice as accurate</em> as <span class="math notranslate nohighlight">\(A_{100}\)</span>. The factor of <span class="math notranslate nohighlight">\(2\)</span> comes from the relation between the square roots of the two sample sizes: <span class="math notranslate nohighlight">\(\sqrt{400} = 20\)</span> is twice as large as <span class="math notranslate nohighlight">\(\sqrt{100} = 10\)</span>.</p>
<p>Accuracy doesn’t come cheap. For double the accuracy, we have to multiply the sample size by a factor of <span class="math notranslate nohighlight">\(2^2 = 4\)</span>. For 5 times the accuracy, we would have to multiply the sample size by a factor of <span class="math notranslate nohighlight">\(5^2 = 25\)</span>.</p>
<p>In other words, if you multiply the sample size by a factor, the accuracy only goes up by the square root of the factor. This is called the <strong>square root law</strong>.</p>
</section>
<section id="concentration-of-probabilities">
<h2><span class="section-number">7.3.5. </span>Concentration of Probabilities<a class="headerlink" href="#concentration-of-probabilities" title="Link to this heading">#</a></h2>
<p>In the figure below, <span class="math notranslate nohighlight">\(A_n\)</span> is proportion of heads in <span class="math notranslate nohighlight">\(n\)</span> tosses of a coin. That is, <span class="math notranslate nohighlight">\(A_n\)</span> is the average of i.i.d. <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span> where each <span class="math notranslate nohighlight">\(X_i\)</span> is an indicator that is 1 with chance <span class="math notranslate nohighlight">\(1/2\)</span>.</p>
<p>The histograms show the distribution of <span class="math notranslate nohighlight">\(A_{100}\)</span> and <span class="math notranslate nohighlight">\(A_{400}\)</span>. Notice that both distributions balance at 0.5, and the distribution of <span class="math notranslate nohighlight">\(A_{400}\)</span> is more concentrated around 0.5.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<img alt="../../_images/fa349eac7bad7e83fc421c421a546eb33505b055f7d8cfaabdf9c3d53cc33524.png" src="../../_images/fa349eac7bad7e83fc421c421a546eb33505b055f7d8cfaabdf9c3d53cc33524.png" />
</div>
</div>
<p>In general, the larger the sample size <span class="math notranslate nohighlight">\(n\)</span>, the more likely it is that the sample average <span class="math notranslate nohighlight">\(A_n\)</span> will be close to the population average <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p>Formally, let <span class="math notranslate nohighlight">\(c &gt; 0\)</span> be any number. Then</p>
<div class="math notranslate nohighlight">
\[
P(\mu - c &lt; A_n &lt; \mu + c) ~ = ~ P(\vert A_n - \mu \vert &lt; c) ~ \to ~ 1 ~~~ \text{ as } n \to \infty
\]</div>
<p>No matter how small <span class="math notranslate nohighlight">\(c\)</span> is, when the sample size is large enough the sample mean is almost certain to be in the interval <span class="math notranslate nohighlight">\(\mu \pm c\)</span>.</p>
<p>This result is called the <strong>Weak Law of Large Numbers</strong> and you can prove it using Chebyshev’s inequality. We will be most interested in the special case where <span class="math notranslate nohighlight">\(A_n\)</span> is a proportion.</p>
</section>
<section id="id1">
<h2><span class="section-number">7.3.6. </span>The Law of Averages<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span> be i.i.d. indicators, each equal to 1 with probability <span class="math notranslate nohighlight">\(p\)</span>. Let <span class="math notranslate nohighlight">\(A_n\)</span> be the sample proportion of 1’s, that is, let <span class="math notranslate nohighlight">\(A_n = S_n/n\)</span> be the sample average.</p>
<p>The formal statement of the <em>law of averages</em> is that for each fixed <span class="math notranslate nohighlight">\(c &gt; 0\)</span>, no matter how small,</p>
<div class="math notranslate nohighlight">
\[
P(p - c &lt; A_n &lt; p + c) ~ = ~ P(\vert A_n - p \vert &lt; c) ~ \to ~ 1 ~~~ \text{ as } n \to \infty
\]</div>
<p>The law of averages says that when the sample size is large, the sample proportion of 1’s is hugely likely to be in a small interval around <span class="math notranslate nohighlight">\(p\)</span>.</p>
<p>But the sample proportion is unlikely to be exactly equal to <span class="math notranslate nohighlight">\(p\)</span>, as we have seen in examples when <span class="math notranslate nohighlight">\(p = 0.5\)</span>.</p>
<p>The law of averages implies that as you keep rolling a die:</p>
<ul class="simple">
<li><p>There is greater chance that the proportion of sixes is in any fixed interval that contains <span class="math notranslate nohighlight">\(1/6\)</span>. For example, as the number of rolls gets larger there is greater chance that the proportion of sixes will be in the range 15% to 18%.</p></li>
<li><p>There is less chance that the proportion of sixes is in any fixed interval that doesn’t contain <span class="math notranslate nohighlight">\(1/6\)</span>. For example, as the number of rolls gets larger there is less chance that the proportion of sixes will be less than 16%.</p></li>
</ul>
<p>There is nothing special about sixes in the discussion above. You could replace “six” with any other face of the die. The result is the same: in a large number of rolls, it is hugely likely that the observed proportion of times the face appears is close to <span class="math notranslate nohighlight">\(1/6\)</span>.</p>
<p>That is why when you repeatedly simulate rolling a die, the entire <em>empirical histogram</em> of the simulated results starts to look like the uniform distribution on 1, 2, 3, 4, 5, 6.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">one_die</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span><span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">die_bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">6.6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">one_die</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">die_bins</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Probability Histogram of the Face on One Roll&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/ac41a52b79e5f47f1720f3f13f4b32e1de54214914a833fc4a3afc5b3f940861.png" src="../../_images/ac41a52b79e5f47f1720f3f13f4b32e1de54214914a833fc4a3afc5b3f940861.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulations</span> <span class="o">=</span> <span class="n">one_die</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">simulations</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">die_bins</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Empirical Histogram of 10,000 Rolls&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/03a234247a40be9e1f1a91a15a8bbd120bd069e154582f1a71d2cf46038621e2.png" src="../../_images/03a234247a40be9e1f1a91a15a8bbd120bd069e154582f1a71d2cf46038621e2.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/Chapter_07"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="02_Sampling_Without_Replacement.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">7.2. </span>Sampling Without Replacement</p>
      </div>
    </a>
    <a class="right-next"
       href="04_Exercises.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">7.4. </span>Exercises</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sample-sum">7.3.1. The Sample Sum</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exactly-half-heads">7.3.2. Exactly Half Heads</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sample-average">7.3.3. The Sample Average</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-square-root-law">7.3.4. The Square Root Law</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concentration-of-probabilities">7.3.5. Concentration of Probabilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">7.3.6. The Law of Averages</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ani Adhikari
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>