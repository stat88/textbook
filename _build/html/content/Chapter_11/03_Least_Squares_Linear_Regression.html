
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>11.3. Least Squares Linear Regression &#8212; Data 88S Textbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/Chapter_11/03_Least_Squares_Linear_Regression';</script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="11.4. Bounds on Correlation" href="04_Bounds_on_Correlation.html" />
    <link rel="prev" title="11.2. Examples" href="02_Examples.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/data88s_logo.png" class="logo__image only-light" alt="Data 88S Textbook - Home"/>
    <script>document.write(`<img src="../../_static/data88s_logo.png" class="logo__image only-dark" alt="Data 88S Textbook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="http://stat88.org">Course Home</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_01/00_The_Basics.html">1. The Basics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/01_Probabilities_as_Proportions.html">1.1. Probabilities as Proportions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/02_Exact_Calculation_or_Bound.html">1.2. Exact Calculation, or Bound?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/03_Fundamental_Rules.html">1.3. Fundamental Rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/04_Exercises.html">1.4. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_02/00_Intersections_and_Conditioning.html">2. Intersections and Conditioning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/01_The_Chance_of_an_Intersection.html">2.1. The Chance of an Intersection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/02_Symmetry_in_Simple_Random_Sampling.html">2.2. Symmetry in Simple Random Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/03_Bayes_Rule.html">2.3. Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/04_Use_and_Interpretation.html">2.4. Use and Interpretation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/05_Independence.html">2.5. Independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/06_Exercises.html">2.6. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_03/00_Random_Counts.html">3. Random Counts</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/01_Success_and_Failure.html">3.1. Success and Failure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/02_Random_Variables.html">3.2. Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/03_The_Binomial_Distribution.html">3.3. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/04_The_Hypergeometric_Distribution.html">3.4. The Hypergeometric Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/05_Examples.html">3.5. Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/06_Exercises.html">3.6. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_04/00_Infinitely_Many_Values.html">4. Infinitely Many Values</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/01_Cumulative_Distribution_Function.html">4.1. Cumulative Distribution Function (CDF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/02_Waiting_Times.html">4.2. Waiting Times</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/03_Exponential_Approximations.html">4.3. Exponential Approximations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/04_The_Poisson_Distribution.html">4.4. The Poisson Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/05_Exercises.html">4.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_05/00_Expectation.html">5. Expectation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/01_Definition.html">5.1. Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/02_Functions_of_Random_Variables.html">5.2. Functions of Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/03_Method_of_Indicators.html">5.3. Method of Indicators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/04_Unbiased_Estimators.html">5.4. Unbiased Estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/05_Conditional_Expectation.html">5.5. Conditional Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/06_Expectation_by_Conditioning.html">5.6. Expectation by Conditioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/07_Exercises.html">5.7. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_06/00_Measuring_Variability.html">6. Measuring Variability</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/01_Variance_and_Standard_Deviation.html">6.1. Variance and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/02_Simplifying_the_Calculation.html">6.2. Simplifying the Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/03_Markovs_Inequality.html">6.3. Markov’s Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/04_Chebyshevs_Inequality.html">6.4. Chebyshev’s Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/05_Exercises.html">6.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_07/00_The_Variance_of_a_Sum.html">7. The Variance of a Sum</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_07/01_Sums_of_Independent_Random_Variables.html">7.1. Sums of Independent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_07/02_Sampling_Without_Replacement.html">7.2. Sampling Without Replacement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_07/03_The_Law_of_Averages.html">7.3. The Law of Averages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_07/04_Exercises.html">7.4. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_08/00_Central_Limit_Theorem.html">8. Central Limit Theorem</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/01_Distribution_of_a_Sample_Sum.html">8.1. The Distribution of a Sample Sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/02_Standard_Normal_Curve.html">8.2. Standard Normal Curve</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/03_Normal_Approximation.html">8.3. Normal Approximation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/04_How_Large_is_Large.html">8.4. How Large is “Large”?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/05_Exercises.html">8.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_09/00_Inference.html">9. Inference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/01_Confidence_Intervals_Method.html">9.1. Confidence Intervals: Method</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/02_Confidence_Intervals_Interpretation.html">9.2. Confidence Intervals: Interpretation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/03_Testing_Hypotheses.html">9.3. Testing Hypotheses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/04_AB_Testing_Fishers_Exact_Test.html">9.4. A/B Testing: Fisher’s Exact Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/05_Exercises.html">9.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_10/00_Probability_Density.html">10. Probability Density</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/01_Density.html">10.1. Density</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/02_Expectation_and_Variance.html">10.2. Expectation and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/03_The_Exponential_Distribution.html">10.3. Exponential Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/04_The_Normal_Distribution.html">10.4. The Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_10/05_Exercises.html">10.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="00_Bias_Variance_and_Least_Squares.html">11. Bias, Variance, and Least Squares</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_Bias_and_Variance.html">11.1. Bias and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_Examples.html">11.2. Examples</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">11.3. Least Squares Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_Bounds_on_Correlation.html">11.4. Bounds on Correlation</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_The_Error_in_Regression.html">11.5. The Error in Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_Exercises.html">11.6. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_12/00_Inference_in_Regression.html">12. Inference in Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_12/01_The_Simple_Linear_Regression_Model.html">12.1. The Simple Linear Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_12/02_The_Distribution_of_the_Estimated_Slope.html">12.2. The Distribution of the Estimated Slope</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_12/03_Towards_Multiple_Regression.html">12.3. Towards Multiple Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_12/04_Exercises.html">12.4. Exercises</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/content/Chapter_11/03_Least_Squares_Linear_Regression.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Least Squares Linear Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-squared-error">11.3.1. Mean Squared Error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#best-intercept-for-a-fixed-slope">11.3.2. Best Intercept for a Fixed Slope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#best-slope">11.3.3. Best Slope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation">11.3.4. Correlation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-familiar-formula-for-the-best-slope">11.3.5. A Familiar Formula for the Best Slope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#equation-of-the-regression-line">11.3.6. Equation of the Regression Line</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="least-squares-linear-regression">
<h1><span class="section-number">11.3. </span>Least Squares Linear Regression<a class="headerlink" href="#least-squares-linear-regression" title="Link to this heading">#</a></h1>
<p>The mean squared error is a criterion by which you can compare two estimators – the one with the smaller mean squared error is on average closer to the quantity you are trying to estimate. An important use of this criterion is to identify the best among a class of estimators.</p>
<p>For example, suppose you have a random pair <span class="math notranslate nohighlight">\((X, Y)\)</span> and you want to use a linear function of <span class="math notranslate nohighlight">\(X\)</span> to estimate <span class="math notranslate nohighlight">\(Y\)</span>. That is, you want to estimate <span class="math notranslate nohighlight">\(Y\)</span> by the function <span class="math notranslate nohighlight">\(aX + b\)</span> for some slope <span class="math notranslate nohighlight">\(a\)</span> and intercept <span class="math notranslate nohighlight">\(b\)</span>. Your goal is to find the best in the class of all linear functions. If the criterion is mean squared error, the goal is to see if there is a slope and an intercept that minimize the mean squared error.</p>
<p>This is the <a class="reference external" href="https://www.inferentialthinking.com/chapters/15/2/Regression_Line.html">regression</a> problem from Data 8, expressed in random variable notation. Recall that in Data 8 you were given formulas for the <a class="reference external" href="https://www.inferentialthinking.com/chapters/15/2/Regression_Line.html#The-Equation-of-the-Regression-Line">slope and intercept</a> of the “best” or “least squares” line, also known as the regression line. In Data 8 notation the formulas are:</p>
<div class="math notranslate nohighlight">
\[
\text{slope of the regression line} ~ = ~ r \frac{\text{SD of }y}{\text{SD of }x}
\]</div>
<p>where <span class="math notranslate nohighlight">\(r\)</span> is the correlation between the two variables (which we have not yet defined in this course), and</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp;\text{intercept of the regression line} \\
&amp;= ~ \text{(average of }y\text{)} - \text{slope}\times\text{(average of }x\text{)}
\end{align*}
\end{split}\]</div>
<p>Data 8 gives you two ways of confirming that the formulas work:</p>
<ul class="simple">
<li><p>By the <a class="reference external" href="https://www.inferentialthinking.com/chapters/15/2/Regression_Line.html#Identifying-the-Line-in-Standard-Units">geometry</a> of elliptical or “football shaped” scatter diagrams</p></li>
<li><p>By <a class="reference external" href="https://www.inferentialthinking.com/chapters/15/3/Method_of_Least_Squares.html#Minimizing-the-Root-Mean-Squared-Error">numerical minimization</a> of the mean squared error over all possible lines</p></li>
</ul>
<p>We will now derive the formulas mathematically using calculus and properties of expectation and variance.</p>
<p>First, some notation:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E(X) = \mu_X\)</span>, <span class="math notranslate nohighlight">\(SD(X) = \sigma_X\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(E(Y) = \mu_Y\)</span>, <span class="math notranslate nohighlight">\(SD(Y) = \sigma_Y\)</span></p></li>
</ul>
<p>Also, some terminology: statistics that we have been calling “estimators” can also be called “predictors” depending on the context. Data 8 calls the regression estimate a regression prediction, and we will do that too.</p>
<section id="mean-squared-error">
<h2><span class="section-number">11.3.1. </span>Mean Squared Error<a class="headerlink" href="#mean-squared-error" title="Link to this heading">#</a></h2>
<p>For the random point <span class="math notranslate nohighlight">\((X, Y)\)</span>, the mean squared error of a linear predictor of <span class="math notranslate nohighlight">\(Y\)</span> based on <span class="math notranslate nohighlight">\(X\)</span> depends on the slope <span class="math notranslate nohighlight">\(a\)</span> and intercept <span class="math notranslate nohighlight">\(b\)</span> of the line used. So let us define <span class="math notranslate nohighlight">\(MSE(a, b)\)</span> to be the mean squared error when we use the line <span class="math notranslate nohighlight">\(aX + b\)</span> to predict <span class="math notranslate nohighlight">\(Y\)</span>. That is,</p>
<div class="math notranslate nohighlight">
\[
MSE(a, b) ~ = ~ E\left( (Y - (aX+b))^2 \right)
\]</div>
<p>We have to find the values of <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> that minimize this function. We will do that by calculus, in two stages.</p>
</section>
<section id="best-intercept-for-a-fixed-slope">
<h2><span class="section-number">11.3.2. </span>Best Intercept for a Fixed Slope<a class="headerlink" href="#best-intercept-for-a-fixed-slope" title="Link to this heading">#</a></h2>
<p>First, we will fix the slope and find the best intercept for that slope. The error can be rewritten as follows:</p>
<div class="math notranslate nohighlight">
\[
Y - (aX+b) ~ = ~ (Y-aX) - b
\]</div>
<p>For a fixed <span class="math notranslate nohighlight">\(a\)</span>, let <span class="math notranslate nohighlight">\(MSE_a(b) = MSE(a, b)\)</span> be considered as a function of <span class="math notranslate nohighlight">\(b\)</span> alone. Then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
MSE_a(b) ~ &amp;= ~ E\left( ((Y-aX) - b)^2 \right) \\
&amp;= ~ E\left( (Y-aX)^2 - 2b(Y-aX) + b^2 \right) \\
&amp;= ~ E\left( (Y-aX)^2\right) -2bE(Y-aX) + b^2
\end{align*}
\end{split}\]</div>
<p>Now</p>
<div class="math notranslate nohighlight">
\[
\frac{d}{db}MSE_a(b) ~ = ~ -2E(Y-aX) + 2b
\]</div>
<p>Set this equal to <span class="math notranslate nohighlight">\(0\)</span> and solve to see that the best intercept <span class="math notranslate nohighlight">\(\hat{b}_a\)</span> for the fixed slope <span class="math notranslate nohighlight">\(a\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\hat{b}_a ~ = ~ E(Y-aX) ~ = ~ \mu_Y - a\mu_X
\]</div>
<p>This is consistent with the formula for the intercept of the regression line in Data 8:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp;\text{intercept of the regression line} \\
&amp;= ~ \text{(average of }y\text{)} - \text{slope}\times\text{(average of }x\text{)}
\end{align*}
\end{split}\]</div>
<p>To be very thorough, we should take the second derivative, look at its sign, and confirm that we have a minimum rather than a maximum value of the mean squared error. But we will spare ourselves that calculation. We have enough experience from Data 8 to know that this is a minimum, not a maximum.</p>
</section>
<section id="best-slope">
<h2><span class="section-number">11.3.3. </span>Best Slope<a class="headerlink" href="#best-slope" title="Link to this heading">#</a></h2>
<p>We now have to find the best among all slopes. For each fixed slope <span class="math notranslate nohighlight">\(a\)</span> we must first plug in the best intercept we just found. Then the error in the prediction can be written as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
Y - (aX+\hat{b}_a) ~ &amp;= Y - (aX + \mu_Y - a\mu_X) \\
&amp;= ~ (Y-\mu_Y) - a(X-\mu_X) \\
&amp;= D_Y - aD_X
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(D_X\)</span> and <span class="math notranslate nohighlight">\(D_Y\)</span> are the deviations of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> from their respective means.</p>
<p>We have to minimize</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
MSE(a) ~ &amp;= ~ E\left( (D_Y - aD_X)^2 \right) \\
&amp;= ~ E(D_Y^2) -2aE(D_XD_Y) + a^2E(D_X^2) \\
&amp;= ~ \sigma_Y^2 -2aE(D_XD_Y) + a^2\sigma_X^2
\end{align*}
\end{split}\]</div>
<p>by the definition of variance. Now</p>
<div class="math notranslate nohighlight">
\[
\frac{d}{da}MSE(a) ~ = ~ -2E(D_XD_Y) + 2a\sigma_X^2
\]</div>
<p>Set this equal to <span class="math notranslate nohighlight">\(0\)</span> and solve to see that the best slope is</p>
<div class="math notranslate nohighlight">
\[
\hat{a} ~ = ~ \frac{E(D_XD_Y)}{\sigma_X^2} ~ = ~ \frac{E\big{(}(X-\mu_X)(Y-\mu_Y)\big{)}}{\sigma_X^2}
\]</div>
<p>This doesn’t look like the Data 8 formula for the slope of the regression line, but it is the way the slope of the regression line is often written. Let’s see if we can make it resemble the Data 8 formula.</p>
</section>
<section id="correlation">
<h2><span class="section-number">11.3.4. </span>Correlation<a class="headerlink" href="#correlation" title="Link to this heading">#</a></h2>
<p>The expected product <span class="math notranslate nohighlight">\(E(D_XD_Y)\)</span> is called the <em>covariance</em> of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. Covariance is difficult to interpret because it has strange units. For example, if we were using educational level to predict income, then the covariance could be measured in units of years<span class="math notranslate nohighlight">\(\times\)</span>dollars, which is hard to understand.</p>
<p>One way to deal with this problem is to first divide each deviation by the corresponding SD, to get a pure number. This converts each variable to standard units. The expected product of standard units is called the <em>correlation coefficient</em> of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, or just correlation for short. We will denote it by <span class="math notranslate nohighlight">\(r(X, Y)\)</span> or just <span class="math notranslate nohighlight">\(r\)</span>.</p>
<div class="math notranslate nohighlight">
\[
r ~ = ~ r(X, Y) ~ = ~ E\Bigg( \left(\frac{X - \mu_X}{\sigma_X}\right)\left(\frac{Y - \mu_Y}{\sigma_Y}\right)\Bigg)
\]</div>
<p>This agrees with the <a class="reference external" href="https://www.inferentialthinking.com/chapters/15/1/Correlation.html#Calculating-$r$">Data 8 definition</a> of correlation, which says, “<span class="math notranslate nohighlight">\(r\)</span> is the average of the products of the two variables, when both variables are measured in standard units.”</p>
<p>We now have</p>
<div class="math notranslate nohighlight">
\[
E(D_XD_Y) ~ = ~ E\big{(}(X-\mu_X)(Y-\mu_Y)\big{)} ~ = ~ r\sigma_X\sigma_Y
\]</div>
</section>
<section id="a-familiar-formula-for-the-best-slope">
<h2><span class="section-number">11.3.5. </span>A Familiar Formula for the Best Slope<a class="headerlink" href="#a-familiar-formula-for-the-best-slope" title="Link to this heading">#</a></h2>
<p>The best slope can be written as</p>
<div class="math notranslate nohighlight">
\[
\hat{a} ~ = ~ \frac{E(D_XD_Y)}{\sigma_X^2} ~ = ~ \frac{r\sigma_X\sigma_Y}{\sigma_X^2} ~ = ~ r\frac{\sigma_Y}{\sigma_X}
\]</div>
<p>which is the same as the Data 8 formula for the slope of the regression line.</p>
</section>
<section id="equation-of-the-regression-line">
<h2><span class="section-number">11.3.6. </span>Equation of the Regression Line<a class="headerlink" href="#equation-of-the-regression-line" title="Link to this heading">#</a></h2>
<p>We have shown that no matter what the joint distribution of the pair <span class="math notranslate nohighlight">\((X, Y)\)</span>, there is a unique straight line that minimizes the mean squared error of prediction among all straight lines. This line is called the <em>regression line</em>, for reasons that you know from Data 8.</p>
<p>The equation of the regression line is</p>
<div class="math notranslate nohighlight">
\[
\hat{Y} ~ = ~ \hat{a}X + \hat{b}
\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{Y}\)</span> is the regression prediction of <span class="math notranslate nohighlight">\(Y\)</span> based on <span class="math notranslate nohighlight">\(X\)</span>, also known as the <em>fitted value</em> of <span class="math notranslate nohighlight">\(Y\)</span></p></li>
<li><p>the slope of the regression line is <span class="math notranslate nohighlight">\(\hat{a} = r\frac{\sigma_Y}{\sigma_X}\)</span></p></li>
<li><p>the intercept of the regression line is <span class="math notranslate nohighlight">\(\hat{b} = \mu_Y - \hat{a}\mu_X\)</span></p></li>
</ul>
<p>Sometimes it is useful to write the regression equation in a different form:</p>
<div class="math notranslate nohighlight">
\[
\hat{Y} ~ = ~ \hat{a}X + \mu_Y - \hat{a}\mu_X
~ = ~ \hat{a}(X - \mu_X) + \mu_Y
\]</div>
<p>This form can reduce calculation because <span class="math notranslate nohighlight">\(E(X - \mu_X) = 0\)</span> and <span class="math notranslate nohighlight">\(Var(X - \mu_X) = Var(X) = \sigma_X^2\)</span>. We will use it in later sections to study the error in the regression prediction.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/Chapter_11"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="02_Examples.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">11.2. </span>Examples</p>
      </div>
    </a>
    <a class="right-next"
       href="04_Bounds_on_Correlation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11.4. </span>Bounds on Correlation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-squared-error">11.3.1. Mean Squared Error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#best-intercept-for-a-fixed-slope">11.3.2. Best Intercept for a Fixed Slope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#best-slope">11.3.3. Best Slope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation">11.3.4. Correlation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-familiar-formula-for-the-best-slope">11.3.5. A Familiar Formula for the Best Slope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#equation-of-the-regression-line">11.3.6. Equation of the Regression Line</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ani Adhikari
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>