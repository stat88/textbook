
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>10.4. The Normal Distribution &#8212; Data 88S Textbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/Chapter_10/04_The_Normal_Distribution';</script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="10.5. Exercises" href="05_Exercises.html" />
    <link rel="prev" title="10.3. Exponential Distribution" href="03_The_Exponential_Distribution.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/data88s_logo.png" class="logo__image only-light" alt="Data 88S Textbook - Home"/>
    <script>document.write(`<img src="../../_static/data88s_logo.png" class="logo__image only-dark" alt="Data 88S Textbook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="http://stat88.org">Course Home</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_01/00_The_Basics.html">1. The Basics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/01_Probabilities_as_Proportions.html">1.1. Probabilities as Proportions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/02_Exact_Calculation_or_Bound.html">1.2. Exact Calculation, or Bound?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/03_Fundamental_Rules.html">1.3. Fundamental Rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_01/04_Exercises.html">1.4. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_02/00_Intersections_and_Conditioning.html">2. Intersections and Conditioning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/01_The_Chance_of_an_Intersection.html">2.1. The Chance of an Intersection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/02_Symmetry_in_Simple_Random_Sampling.html">2.2. Symmetry in Simple Random Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/03_Bayes_Rule.html">2.3. Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/04_Use_and_Interpretation.html">2.4. Use and Interpretation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/05_Independence.html">2.5. Independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_02/06_Exercises.html">2.6. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_03/00_Random_Counts.html">3. Random Counts</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/01_Success_and_Failure.html">3.1. Success and Failure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/02_Random_Variables.html">3.2. Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/03_The_Binomial_Distribution.html">3.3. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/04_The_Hypergeometric_Distribution.html">3.4. The Hypergeometric Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/05_Examples.html">3.5. Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_03/06_Exercises.html">3.6. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_04/00_Infinitely_Many_Values.html">4. Infinitely Many Values</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/01_Cumulative_Distribution_Function.html">4.1. Cumulative Distribution Function (CDF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/02_Waiting_Times.html">4.2. Waiting Times</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/03_Exponential_Approximations.html">4.3. Exponential Approximations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/04_The_Poisson_Distribution.html">4.4. The Poisson Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_04/05_Exercises.html">4.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_05/00_Expectation.html">5. Expectation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/01_Definition.html">5.1. Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/02_Functions_of_Random_Variables.html">5.2. Functions of Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/03_Method_of_Indicators.html">5.3. Method of Indicators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/04_Unbiased_Estimators.html">5.4. Unbiased Estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/05_Conditional_Expectation.html">5.5. Conditional Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/06_Expectation_by_Conditioning.html">5.6. Expectation by Conditioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_05/07_Exercises.html">5.7. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_06/00_Measuring_Variability.html">6. Measuring Variability</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/01_Variance_and_Standard_Deviation.html">6.1. Variance and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/02_Simplifying_the_Calculation.html">6.2. Simplifying the Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/03_Markovs_Inequality.html">6.3. Markov’s Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/04_Chebyshevs_Inequality.html">6.4. Chebyshev’s Inequality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_06/05_Exercises.html">6.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_07/00_The_Variance_of_a_Sum.html">7. The Variance of a Sum</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_07/01_Sums_of_Independent_Random_Variables.html">7.1. Sums of Independent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_07/02_Sampling_Without_Replacement.html">7.2. Sampling Without Replacement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_07/03_The_Law_of_Averages.html">7.3. The Law of Averages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_07/04_Exercises.html">7.4. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_08/00_Central_Limit_Theorem.html">8. Central Limit Theorem</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/01_Distribution_of_a_Sample_Sum.html">8.1. The Distribution of a Sample Sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/02_Standard_Normal_Curve.html">8.2. Standard Normal Curve</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/03_Normal_Approximation.html">8.3. Normal Approximation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/04_How_Large_is_Large.html">8.4. How Large is “Large”?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_08/05_Exercises.html">8.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_09/00_Inference.html">9. Inference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/01_Confidence_Intervals_Method.html">9.1. Confidence Intervals: Method</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/02_Confidence_Intervals_Interpretation.html">9.2. Confidence Intervals: Interpretation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/03_Testing_Hypotheses.html">9.3. Testing Hypotheses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/04_AB_Testing_Fishers_Exact_Test.html">9.4. A/B Testing: Fisher’s Exact Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_09/05_Exercises.html">9.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="00_Probability_Density.html">10. Probability Density</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_Density.html">10.1. Density</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_Expectation_and_Variance.html">10.2. Expectation and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_The_Exponential_Distribution.html">10.3. Exponential Distribution</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">10.4. The Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_Exercises.html">10.5. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_11/00_Bias_Variance_and_Least_Squares.html">11. Bias, Variance, and Least Squares</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/01_Bias_and_Variance.html">11.1. Bias and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/02_Examples.html">11.2. Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/03_Least_Squares_Linear_Regression.html">11.3. Least Squares Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/04_Bounds_on_Correlation.html">11.4. Bounds on Correlation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/05_The_Error_in_Regression.html">11.5. The Error in Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_11/06_Exercises.html">11.6. Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Chapter_12/00_Inference_in_Regression.html">12. Inference in Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_12/01_The_Simple_Linear_Regression_Model.html">12.1. The Simple Linear Regression Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_12/02_The_Distribution_of_the_Estimated_Slope.html">12.2. The Distribution of the Estimated Slope</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_12/03_Towards_Multiple_Regression.html">12.3. Towards Multiple Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Chapter_12/04_Exercises.html">12.4. Exercises</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/content/Chapter_10/04_The_Normal_Distribution.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The Normal Distribution</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sums-of-independent-normal-variables">10.4.1. Sums of Independent Normal Variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#confidence-interval-for-the-difference-between-means">10.4.2. Confidence Interval for the Difference Between Means</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-for-the-equality-of-two-means">10.4.3. Test for the Equality of Two Means</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#confidence-interval-for-the-difference-between-proportions">10.4.4. Confidence Interval for the Difference Between Proportions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-for-the-equality-of-two-proportions">10.4.5. Test for the Equality of Two Proportions</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="cell tag_remove_input docutils container">
</div>
<section id="the-normal-distribution">
<h1><span class="section-number">10.4. </span>The Normal Distribution<a class="headerlink" href="#the-normal-distribution" title="Link to this heading">#</a></h1>
<p>We can now think of the normal distribution as the distribution of a random variable that has values on the whole number line, instead of just as a mathematical approximation to other distributions.</p>
<p>The random variable <span class="math notranslate nohighlight">\(X\)</span> has the <em>normal</em> <span class="math notranslate nohighlight">\((\mu, \sigma^2)\)</span> distribution if the density of <span class="math notranslate nohighlight">\(X\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
f(x) ~ = ~ \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{1}{2}\big{(}\frac{x-\mu}{\sigma}\big{)}^2}, ~~~~ -\infty &lt; x &lt; \infty
\]</div>
<p>This is the familiar normal curve we have been using for a while.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<img alt="../../_images/ef440edd8a748d795e87b6d94907735f43e73b59ab9b737d461f8c509d407dd1.png" src="../../_images/ef440edd8a748d795e87b6d94907735f43e73b59ab9b737d461f8c509d407dd1.png" />
</div>
</div>
<p>The random variable <span class="math notranslate nohighlight">\(Z\)</span> has the <em>standard normal distribution</em> if the distribution of <span class="math notranslate nohighlight">\(Z\)</span> is normal <span class="math notranslate nohighlight">\((0, 1)\)</span>. The cdf of <span class="math notranslate nohighlight">\(Z\)</span> is the familiar standard normal cdf <span class="math notranslate nohighlight">\(\Phi\)</span>.</p>
<p>If <span class="math notranslate nohighlight">\(X\)</span> has the normal <span class="math notranslate nohighlight">\((\mu, \sigma^2)\)</span> distribution then</p>
<div class="math notranslate nohighlight">
\[
P(X &lt; x) ~ = ~ P\left(Z &lt; \frac{x - \mu}{\sigma}\right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(Z = \frac{X - \mu}{\sigma}\)</span> is what we have been calling “<span class="math notranslate nohighlight">\(X\)</span> in standard units”. As before, conversions back and forth between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Z\)</span> will be useful for calculations. To get from <span class="math notranslate nohighlight">\(Z\)</span> to <span class="math notranslate nohighlight">\(X\)</span>, use <span class="math notranslate nohighlight">\(X = \sigma Z + \mu\)</span>.</p>
<p>We have been treating the parameters <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> like the mean and the SD of the distribution, and indeed it turns out (after calculations that we will not do) that:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E(X) = \mu\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(SD(X) = \sigma\)</span></p></li>
</ul>
<section id="sums-of-independent-normal-variables">
<h2><span class="section-number">10.4.1. </span>Sums of Independent Normal Variables<a class="headerlink" href="#sums-of-independent-normal-variables" title="Link to this heading">#</a></h2>
<p>We will use (without proof) an important result:</p>
<p>If <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are independent normal random variables then <span class="math notranslate nohighlight">\(X+Y\)</span> also has a normal distribution.</p>
<p>You can test this out by simulation, or take a higher level course to see a mathematical proof. The result should seem reasonable, however, so let’s proceed to use it.</p>
<p>First, we should identify the parameters of the normal distribution of <span class="math notranslate nohighlight">\(X+Y\)</span>. Define the notation</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E(X) = \mu_X\)</span>, <span class="math notranslate nohighlight">\(Var(X) = \sigma^2_X\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(E(Y) = \mu_Y\)</span>, <span class="math notranslate nohighlight">\(Var(Y) = \sigma^2_Y\)</span></p></li>
</ul>
<p>Then</p>
<div class="math notranslate nohighlight">
\[
E(X+Y) ~ = ~ \mu_X + \mu_Y ~~~~~~~~~~~ Var(X+Y) = \sigma^2_X + \sigma^2_Y
\]</div>
<p>The additivity of the variance is due to the independence of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>This result can be extended to any linear combination of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. For example, <span class="math notranslate nohighlight">\(X -2Y + 3\)</span> has the normal distribution with mean <span class="math notranslate nohighlight">\(\mu_X -2\mu_Y + 3\)</span> and variance <span class="math notranslate nohighlight">\(\sigma_X^2 + 4\sigma_Y^2\)</span>. These parameters follow from properties of means and variances, not from any property of the normal distribution.</p>
<p>A particularly important linear combination is the difference <span class="math notranslate nohighlight">\(X-Y\)</span> which is normal <span class="math notranslate nohighlight">\((\mu_X - \mu_Y, \sigma_X^2+\sigma_Y^2)\)</span>. It is used in inference as in the following examples.</p>
</section>
<section id="confidence-interval-for-the-difference-between-means">
<h2><span class="section-number">10.4.2. </span>Confidence Interval for the Difference Between Means<a class="headerlink" href="#confidence-interval-for-the-difference-between-means" title="Link to this heading">#</a></h2>
<p>Suppose <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(m\)</span> are large sample sizes, and suppose you have two independent samples as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span> are i.i.d. with mean <span class="math notranslate nohighlight">\(\mu_X\)</span> and SD <span class="math notranslate nohighlight">\(\sigma_X\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Y_1, Y_2, \ldots, Y_m\)</span> are i.i.d. with mean <span class="math notranslate nohighlight">\(\mu_Y\)</span> and SD <span class="math notranslate nohighlight">\(\sigma_Y\)</span></p></li>
</ul>
<p>Now suppose you want to estimate the difference <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span>. This is the difference between the population means.</p>
<p>Let <span class="math notranslate nohighlight">\(\bar{X}\)</span> and <span class="math notranslate nohighlight">\(\bar{Y}\)</span> be the two sample means. A natural estimator of <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span> is <span class="math notranslate nohighlight">\(\bar{X} - \bar{Y}\)</span>, the difference between the sample means.</p>
<p>By the Central Limit Theorem, the distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> is approximately normal, as is the distribution of <span class="math notranslate nohighlight">\(\bar{Y}\)</span>. We also know the parameters:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\bar{X}\)</span> is approximately normal <span class="math notranslate nohighlight">\((\mu_X, \frac{\sigma_X^2}{n})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\bar{Y}\)</span> is approximately normal <span class="math notranslate nohighlight">\((\mu_Y, \frac{\sigma_Y^2}{m})\)</span></p></li>
</ul>
<p>Therefore by the independence of the two samples,</p>
<div class="math notranslate nohighlight">
\[
\bar{X} - \bar{Y} ~ \text{ is approximately normal } \left(\mu_X - \mu_Y, \frac{\sigma_X^2}{n} + \frac{\sigma_Y^2}{m} \right)
\]</div>
<p>So an approximate 95% confidence interval for <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\bar{X} - \bar{Y} ~ \pm ~ 2\sqrt{ \frac{\sigma_X^2}{n} + \frac{\sigma_Y^2}{m} }
\]</div>
<p>As an example, suppose you have drawn samples of people independently from two cities, and suppose you have collected the following data.</p>
<ul class="simple">
<li><p>The incomes of the 400 sampled people in City X have an average of 70,000 dollars and an SD of 40,000 dollars.</p></li>
<li><p>The incomes of the 600 sampled people in City Y have an average of 80,000 dollars and an SD of 50,000 dollars.</p></li>
</ul>
<p>To construct a confidence interval for the difference between the mean incomes in the two cities, let’s define “difference” to be “mean of City X minus mean of City Y”.</p>
<p>The center of the confidence interval is the observed value of <span class="math notranslate nohighlight">\(\bar{X} - \bar{Y}\)</span>, the difference between the two sample means. An approximate 95% confidence interval for the difference between the two population means is given by</p>
<div class="math notranslate nohighlight">
\[
-10000 ~ \pm ~ 2\sqrt{ \frac{\sigma_X^2}{400} + \frac{\sigma_Y^2}{600} }
\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma_X^2\)</span> is the mean income in City X and <span class="math notranslate nohighlight">\(\sigma_Y^2\)</span> is the mean income in City Y. The trouble is that we don’t know those two numbers. But as we have done so often before, we can estimate the variance we need by substituting the sample variances.</p>
<div class="math notranslate nohighlight">
\[
\sqrt{\frac{\sigma_X^2}{400} + \frac{\sigma_Y^2}{600}} ~ \approx ~ \sqrt{\frac{40000^2}{400} + \frac{50000^2}{600}} ~ \approx ~ 2858
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span> <span class="p">(</span><span class="mi">40000</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mi">400</span> <span class="o">+</span> <span class="p">(</span><span class="mi">50000</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mi">600</span> <span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2857.738033247041
</pre></div>
</div>
</div>
</div>
<p>An approximate 95% confidence interval for the difference between the two population means is therefore given by</p>
<div class="math notranslate nohighlight">
\[
-10000 ~ \pm ~ 2\times2858 ~ \approx ~ (-15716, -4824)
\]</div>
<p>It’s fine for the endpoints to be negative. We are estimating a difference. Since we have calculated the difference in the order “mean of X minus mean of Y”, what we are seeing is just that City <span class="math notranslate nohighlight">\(X\)</span> appears to have a smaller mean than City <span class="math notranslate nohighlight">\(Y\)</span>.</p>
</section>
<section id="test-for-the-equality-of-two-means">
<h2><span class="section-number">10.4.3. </span>Test for the Equality of Two Means<a class="headerlink" href="#test-for-the-equality-of-two-means" title="Link to this heading">#</a></h2>
<p>Also known as an A/B test, this test attempts to decide whether the two underlying population means are the same.</p>
<p>With the data as in the example above, suppose we test the following hypotheses.</p>
<p><span class="math notranslate nohighlight">\(H_0\)</span>: The mean income in City X is the same as the mean income in City Y; that is, <span class="math notranslate nohighlight">\(\mu_X = \mu_Y\)</span>.</p>
<p><span class="math notranslate nohighlight">\(H_A\)</span>: The mean income in City Y is greater than that in City X; that is, <span class="math notranslate nohighlight">\(\mu_Y &gt; \mu_X\)</span>.</p>
<p>It is important to keep in mind that the hypothese are just about the two population means. The null hypothesis is not saying that the two population distributions are the same. It is just saying that the two means are the same. The SDs might be different, the shapes might be different – the null hypothesis makes no claim about those.</p>
<p>A natural test statistic is <span class="math notranslate nohighlight">\(\bar{Y} - \bar{X}\)</span>. Large values of this statistic favor the alternative.</p>
<p>Under <span class="math notranslate nohighlight">\(H_0\)</span>, the distribution of <span class="math notranslate nohighlight">\(\bar{Y} - \bar{X}\)</span> is approximately normal with mean <span class="math notranslate nohighlight">\(0\)</span> and standard deviation</p>
<div class="math notranslate nohighlight">
\[
\sqrt{\frac{\sigma_X^2}{400} + \frac{\sigma_Y^2}{600}}  \approx  \sqrt{\frac{40000^2}{400} + \frac{50000^2}{600}}  \approx  2858
\]</div>
<p>as before.</p>
<p>The observed value of the statistic is <span class="math notranslate nohighlight">\(80000 - 70000 = 10000\)</span> dollars. This is the red dot on the horizontal axis of the figure below.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<img alt="../../_images/b8540758124b1336146c307b6d6584036ff9e34be9828b9dac9132451aaeb13a.png" src="../../_images/b8540758124b1336146c307b6d6584036ff9e34be9828b9dac9132451aaeb13a.png" />
</div>
</div>
<p>The observed statistic is out in a tail of the distribution of the test statistic under the null hypothesis. So the data are not consistent with the null hypothesis. They support the hypothesis that City Y has the higher mean income.</p>
<p>The conclusion is clear from the figure. But if you want to compute a <span class="math notranslate nohighlight">\(p\)</span>-value, it would be approximately</p>
<div class="math notranslate nohighlight">
\[
1 - \Phi\left(\frac{10000-0}{2858}\right) ~ = ~ 1 - \Phi(3.5) ~ = ~ 0.02\%
\]</div>
<p>which is tiny. The data support the alternative hypothesis.</p>
</section>
<section id="confidence-interval-for-the-difference-between-proportions">
<h2><span class="section-number">10.4.4. </span>Confidence Interval for the Difference Between Proportions<a class="headerlink" href="#confidence-interval-for-the-difference-between-proportions" title="Link to this heading">#</a></h2>
<p>This is the special case of the above when the <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> samples both consist of 0’s and 1’s.</p>
<p>Assuming the sample sizes <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(m\)</span> to be large as before, suppose:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span> are i.i.d. Bernoulli <span class="math notranslate nohighlight">\((p_X)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Y_1, Y_2, \ldots, Y_n\)</span> are i.i.d. Bernoulli <span class="math notranslate nohighlight">\((p_Y)\)</span></p></li>
</ul>
<p>Then the difference between the two sample proportions is <span class="math notranslate nohighlight">\(\bar{X} - \bar{Y}\)</span> is a natural estimator for <span class="math notranslate nohighlight">\(p_X - p_Y\)</span>, the difference between the two population proportions.</p>
<div class="math notranslate nohighlight">
\[
\bar{X} - \bar{Y} ~ \text{ is approximately normal } \left(p_X - p_Y, \frac{p_Xq_X}{n} + \frac{p_Yq_Y}{m} \right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(q_X = 1 - p_X\)</span> and <span class="math notranslate nohighlight">\(q_Y = 1 - p_Y\)</span>. We have used the formula <span class="math notranslate nohighlight">\(pq\)</span> for the variance of a Bernoulli <span class="math notranslate nohighlight">\((p)\)</span> random variable. The Bernoulli distribution is so simple – just 0 and 1 as the possible values – that <span class="math notranslate nohighlight">\(p\)</span> determines both the mean and the variance.</p>
<p>Now suppose we have independent samples from two cities, and:</p>
<ul class="simple">
<li><p>37% of the City <span class="math notranslate nohighlight">\(X\)</span> sample are undecided about who they want as President</p></li>
<li><p>28% of the City <span class="math notranslate nohighlight">\(Y\)</span> sample are undecided about who they want as President</p></li>
</ul>
<p>We can construct a confidence interval for the difference between the percents of undecided people in City X and City Y, again taking the difference in the direction “X minus Y”.</p>
<p>The center of the interval is the observed difference between the two sample proportions, <span class="math notranslate nohighlight">\(0.37 - 0.28 = 0.09\)</span>. An approximate 95% confidence interval for the difference between the proportions in the two cities is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; 0.1 ~ \pm ~ 2 \sqrt{ \frac{p_Xq_X}{400} + \frac{p_Yq_Y}{600} } \\
\approx ~ &amp; 0.09 ~ \pm ~ 2 \sqrt{ \frac{0.37\times0.63}{400} + \frac{0.28\times0.72}{600} } \\
\approx ~ &amp; 0.09 ~ \pm ~ 2\times0.0303 \\
\approx ~ &amp; (0.0294, 0.1506)
\end{align*}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span> <span class="p">(</span><span class="mf">0.37</span> <span class="o">*</span> <span class="mf">0.63</span> <span class="o">/</span> <span class="mi">400</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.28</span> <span class="o">*</span> <span class="mf">0.72</span> <span class="o">/</span> <span class="mi">600</span><span class="p">)</span> <span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.030310889132455353
</pre></div>
</div>
</div>
</div>
<p>An approximate 95% confidence interval for the difference between the percents of undecided people in City X and City Y is <span class="math notranslate nohighlight">\(2.94\%\)</span> to <span class="math notranslate nohighlight">\(15.06\%\)</span>.</p>
</section>
<section id="test-for-the-equality-of-two-proportions">
<h2><span class="section-number">10.4.5. </span>Test for the Equality of Two Proportions<a class="headerlink" href="#test-for-the-equality-of-two-proportions" title="Link to this heading">#</a></h2>
<p>We can also use the data to test whether the two underlying population proportions are the same. The calculation involves many of the same moves as in the calculation of the confidence interval above, with one major difference.</p>
<p>Suppose our hypotheses are:</p>
<p><span class="math notranslate nohighlight">\(H_0\)</span>: <span class="math notranslate nohighlight">\(p_X = p_Y = p\)</span>; here <span class="math notranslate nohighlight">\(p\)</span> is just a name we are giving to the common value of <span class="math notranslate nohighlight">\(p_X\)</span> and <span class="math notranslate nohighlight">\(p_Y\)</span></p>
<p><span class="math notranslate nohighlight">\(H_A\)</span>: <span class="math notranslate nohighlight">\(p_X &gt; p_Y\)</span></p>
<p>A natural test statistic is <span class="math notranslate nohighlight">\(\bar{X} - \bar{Y}\)</span>, the difference between the two sample proportions. Large values of the statistic favor the alternative hypothesis.</p>
<p>Under <span class="math notranslate nohighlight">\(H_0\)</span>, the distribution of <span class="math notranslate nohighlight">\(\bar{X} - \bar{Y}\)</span> is approximately normal with mean <span class="math notranslate nohighlight">\(0\)</span> and variance</p>
<div class="math notranslate nohighlight">
\[
\frac{pq}{400} + \frac{pq}{600}
\]</div>
<p>Because we are working under the null hypothesis, we must use the same value for <span class="math notranslate nohighlight">\(p_X\)</span> and <span class="math notranslate nohighlight">\(p_Y\)</span>. This makes the expected difference equal to 0. But also, since the variance of a Bernoulli random variable depends only on <span class="math notranslate nohighlight">\(p\)</span>, it affects the calculation of the variance. Two zero-one populations can’t have the same proportion of ones but different variances.</p>
<p>This is the only way in which the calculation differs from that of the confidence interval which does not make any hypotheses about equality.</p>
<p>So now we have to estimate this common value of <span class="math notranslate nohighlight">\(p\)</span>. Under <span class="math notranslate nohighlight">\(H_0\)</span>, we can think of the combined sample as one gigantic sample of 1000 i.i.d. Bernoulli <span class="math notranslate nohighlight">\((p)\)</span> random variables. To estimate <span class="math notranslate nohighlight">\(p\)</span>, we will use the proportion of ones in the combined sample. This is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\hat{p} ~ &amp;= ~ \frac{0.37\times400 ~ + ~ 0.26\times600}{1000} \\
&amp;= ~ 0.37\times0.4 ~ + ~ 0.26\times0.6\\
&amp;= ~ 0.316
\end{align*}
\end{split}\]</div>
<p>Notice that <span class="math notranslate nohighlight">\(\hat{p}\)</span> is the weighted average of the two sample proportions, where the weights are the sample sizes.</p>
<p>Thus under <span class="math notranslate nohighlight">\(H_0\)</span>, the test statistic <span class="math notranslate nohighlight">\(\bar{X} - \bar{Y}\)</span> is approximately normal with mean <span class="math notranslate nohighlight">\(0\)</span> and SD</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp; \sqrt{ \frac{pq}{400} + \frac{pq}{600} } \\
\approx ~ &amp; \sqrt{ \frac{0.316\times0.684}{400} + \frac{0.316\times0.684}{600} }\\
\approx ~ &amp; 0.03
\end{align*}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span> <span class="mf">0.316</span><span class="o">*</span><span class="mf">0.684</span><span class="o">/</span><span class="mi">400</span> <span class="o">+</span> <span class="mf">0.316</span><span class="o">*</span><span class="mf">0.684</span><span class="o">/</span><span class="mi">600</span> <span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.03000999833388866
</pre></div>
</div>
</div>
</div>
<p>The observed value of the test statistic is <span class="math notranslate nohighlight">\(0.37 - 0.28 = 0.09\)</span>. This is the red dot in the figure below.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<img alt="../../_images/bf86e4ee842b2d699503c8d687f2be41722aaea027ee0e4b4c09bc92968b0059.png" src="../../_images/bf86e4ee842b2d699503c8d687f2be41722aaea027ee0e4b4c09bc92968b0059.png" />
</div>
</div>
<p>The observed value 0.09 is in a tail of the distribution, three standard deviations away from what is expected under the null hypothesis. The data are not consistent with the null hypothesis. They favor the alternative hypothesis that the percent of undecided people in City X is greater than that in City Y.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/Chapter_10"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="03_The_Exponential_Distribution.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">10.3. </span>Exponential Distribution</p>
      </div>
    </a>
    <a class="right-next"
       href="05_Exercises.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">10.5. </span>Exercises</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sums-of-independent-normal-variables">10.4.1. Sums of Independent Normal Variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#confidence-interval-for-the-difference-between-means">10.4.2. Confidence Interval for the Difference Between Means</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-for-the-equality-of-two-means">10.4.3. Test for the Equality of Two Means</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#confidence-interval-for-the-difference-between-proportions">10.4.4. Confidence Interval for the Difference Between Proportions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-for-the-equality-of-two-proportions">10.4.5. Test for the Equality of Two Proportions</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ani Adhikari
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>